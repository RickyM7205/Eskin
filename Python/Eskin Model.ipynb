{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mediterranean-increase",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "nominated-fancy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.98 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import pandas as pd  #\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt  \n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import random\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-survival",
   "metadata": {},
   "source": [
    "## Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "subject-timothy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        1440\n",
       "2        1440\n",
       "3        1440\n",
       "4        1440\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y = pd.read_csv(r'data/eskin_output.csv',header=None)\n",
    "df_y = pd.DataFrame(df_y)\n",
    "df_y.columns = ['label']\n",
    "#df_y.head()\n",
    "df_y = df_y.replace('poke',1)\n",
    "df_y = df_y.replace('rub',2)\n",
    "df_y = df_y.replace('slap',3)\n",
    "df_y = df_y.replace('stroke',4)\n",
    "df_y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-figure",
   "metadata": {},
   "source": [
    "## Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thorough-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat = pd.read_csv(r'data/eskin_stats.csv',header=None)\n",
    "df_stat = pd.DataFrame(df_stat)\n",
    "#df_stat.head()\n",
    "\n",
    "res_stat = df_stat\n",
    "stats_col = ['m1','m2','m3','m4','m5','m6','m7','m8','m9','mt',\n",
    "             'st1','st2','st3','st4','st5','st6','st7','st8','st9','std',\n",
    "             'va1','va2','va3','va4','va5','va6','va7','va8','va9','var',\n",
    "             'ma1','ma2','ma3','ma4','ma5','ma6','ma7','ma8','ma9','mad',\n",
    "             'max1','max2','max3','max4','max5','max6','max7','max8','max9','maxt',\n",
    "             'min1','min2','min3','min4','min5','min6','min7','min8','min9','mint',\n",
    "             'ran1','ran2','ran3','ran4','ran5','ran6','ran7','ran8','ran9','rant',\n",
    "             'sma','e1','e2','e3','e4','e5','e6','e7','e8','e9','et',\n",
    "             'iq1','iq2','iq3','iq4','iq5','iq6','iq7','iq8','iq9','iqrt']\n",
    "\n",
    "res_stat.columns = stats_col "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "massive-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = pd.read_csv(r'data/eskin_stats_fft.csv',header=None)\n",
    "si = pd.DataFrame(si)\n",
    "\n",
    "for t in si.columns:\n",
    "    #print(si[t].dtypes)\n",
    "    if si[t].dtypes == 'object':\n",
    "        #print(si[t])\n",
    "        si[t] = si[t].str.replace('i','j')\n",
    "        si[t] = si[t].str.replace(' ','')\n",
    "        si[t] = si[t].str.replace('\\ndtype:complex128','')\n",
    "        si[t] = si[t].str.replace('\\ndtype:float64','')\n",
    "        si[t] = si[t].str.replace('NaN','')\n",
    "        si[t] = si[t].str.replace('0-','-')\n",
    "        si[t] = si[t].str.replace(')','')\n",
    "        si[t] = si[t].str.replace('(','')\n",
    "        #print(si[t])\n",
    "        si[t] = si[t].apply(lambda x: np.complex(x))\n",
    "        #print(si[t])\n",
    "res_fft = si\n",
    "\n",
    "fft_col = ['f_m1','f_m2','f_m3','f_m4','f_m5','f_m6','f_m7','f_m8','f_m9','f_mt',\n",
    "             'f_st1','f_st2','f_st3','f_st4','f_st5','f_st6','f_st7','f_st8','f_st9','f_std',\n",
    "             'f_va1','f_va2','f_va3','f_va4','f_va5','f_va6','f_va7','f_va8','f_va9','f_var',\n",
    "             'f_ma1','f_ma2','f_ma3','f_ma4','f_ma5','f_ma6','f_ma7','f_ma8','f_ma9','f_mad',\n",
    "             'f_max1','f_max2','f_max3','f_max4','f_max5','f_max6','f_max7','f_max8','f_max9','f_maxt',\n",
    "             'f_min1','f_min2','f_min3','f_min4','f_min5','f_min6','f_min7','f_min8','f_min9','f_mint',\n",
    "             'f_ran1','f_ran2','f_ran3','f_ran4','f_ran5','f_ran6','f_ran7','f_ran8','f_ran9','f_rant',\n",
    "             'f_sma','f_e1','f_e2','f_e3','f_e4','f_e5','f_e6','f_e7','f_e8','f_e9','f_et',\n",
    "             'f_iq1','f_iq2','f_iq3','f_iq4','f_iq5','f_iq6','f_iq7','f_iq8','f_iq9','f_iqrt']\n",
    "\n",
    "res_fft.columns = fft_col\n",
    "\n",
    "res_fft = res_fft.applymap(np.absolute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "previous-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>m4</th>\n",
       "      <th>m5</th>\n",
       "      <th>m6</th>\n",
       "      <th>m7</th>\n",
       "      <th>m8</th>\n",
       "      <th>m9</th>\n",
       "      <th>mt</th>\n",
       "      <th>...</th>\n",
       "      <th>f_iq1</th>\n",
       "      <th>f_iq2</th>\n",
       "      <th>f_iq3</th>\n",
       "      <th>f_iq4</th>\n",
       "      <th>f_iq5</th>\n",
       "      <th>f_iq6</th>\n",
       "      <th>f_iq7</th>\n",
       "      <th>f_iq8</th>\n",
       "      <th>f_iq9</th>\n",
       "      <th>f_iqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.177778</td>\n",
       "      <td>41.044444</td>\n",
       "      <td>44.522222</td>\n",
       "      <td>59.300000</td>\n",
       "      <td>73.244444</td>\n",
       "      <td>60.322222</td>\n",
       "      <td>56.977778</td>\n",
       "      <td>69.855556</td>\n",
       "      <td>55.388889</td>\n",
       "      <td>56.981481</td>\n",
       "      <td>...</td>\n",
       "      <td>441.040214</td>\n",
       "      <td>475.770372</td>\n",
       "      <td>686.422356</td>\n",
       "      <td>562.510183</td>\n",
       "      <td>647.224406</td>\n",
       "      <td>647.224406</td>\n",
       "      <td>562.510183</td>\n",
       "      <td>686.422356</td>\n",
       "      <td>475.770372</td>\n",
       "      <td>590.006178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.988889</td>\n",
       "      <td>68.444444</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>61.166667</td>\n",
       "      <td>70.088889</td>\n",
       "      <td>59.588889</td>\n",
       "      <td>51.922222</td>\n",
       "      <td>45.711111</td>\n",
       "      <td>44.688889</td>\n",
       "      <td>58.422222</td>\n",
       "      <td>...</td>\n",
       "      <td>511.632988</td>\n",
       "      <td>502.491063</td>\n",
       "      <td>542.115355</td>\n",
       "      <td>482.229770</td>\n",
       "      <td>916.884994</td>\n",
       "      <td>916.884994</td>\n",
       "      <td>482.229770</td>\n",
       "      <td>542.115355</td>\n",
       "      <td>502.491063</td>\n",
       "      <td>491.380149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.088889</td>\n",
       "      <td>43.633333</td>\n",
       "      <td>44.533333</td>\n",
       "      <td>83.066667</td>\n",
       "      <td>67.933333</td>\n",
       "      <td>52.477778</td>\n",
       "      <td>52.411111</td>\n",
       "      <td>45.533333</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>54.067901</td>\n",
       "      <td>...</td>\n",
       "      <td>342.123918</td>\n",
       "      <td>528.351686</td>\n",
       "      <td>572.593738</td>\n",
       "      <td>785.070872</td>\n",
       "      <td>634.955719</td>\n",
       "      <td>634.955719</td>\n",
       "      <td>785.070872</td>\n",
       "      <td>572.593738</td>\n",
       "      <td>528.351686</td>\n",
       "      <td>2659.003215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76.633333</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>63.288889</td>\n",
       "      <td>154.366667</td>\n",
       "      <td>107.688889</td>\n",
       "      <td>92.022222</td>\n",
       "      <td>102.311111</td>\n",
       "      <td>68.300000</td>\n",
       "      <td>64.022222</td>\n",
       "      <td>87.114815</td>\n",
       "      <td>...</td>\n",
       "      <td>1199.087034</td>\n",
       "      <td>1107.890541</td>\n",
       "      <td>866.829986</td>\n",
       "      <td>842.717586</td>\n",
       "      <td>878.426867</td>\n",
       "      <td>878.426867</td>\n",
       "      <td>842.717586</td>\n",
       "      <td>866.829986</td>\n",
       "      <td>1107.890541</td>\n",
       "      <td>1091.394490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.700000</td>\n",
       "      <td>31.333333</td>\n",
       "      <td>41.577778</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>35.677778</td>\n",
       "      <td>65.966667</td>\n",
       "      <td>79.611111</td>\n",
       "      <td>30.533333</td>\n",
       "      <td>47.644444</td>\n",
       "      <td>46.504938</td>\n",
       "      <td>...</td>\n",
       "      <td>673.920234</td>\n",
       "      <td>1246.701313</td>\n",
       "      <td>595.913625</td>\n",
       "      <td>468.292469</td>\n",
       "      <td>443.726750</td>\n",
       "      <td>443.726750</td>\n",
       "      <td>468.292469</td>\n",
       "      <td>595.913625</td>\n",
       "      <td>1246.701313</td>\n",
       "      <td>484.947378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>48.933333</td>\n",
       "      <td>37.811111</td>\n",
       "      <td>42.133333</td>\n",
       "      <td>85.911111</td>\n",
       "      <td>62.555556</td>\n",
       "      <td>68.033333</td>\n",
       "      <td>105.711111</td>\n",
       "      <td>75.911111</td>\n",
       "      <td>75.444444</td>\n",
       "      <td>66.938272</td>\n",
       "      <td>...</td>\n",
       "      <td>734.803565</td>\n",
       "      <td>603.324825</td>\n",
       "      <td>503.941105</td>\n",
       "      <td>497.120977</td>\n",
       "      <td>789.305868</td>\n",
       "      <td>789.305868</td>\n",
       "      <td>497.120977</td>\n",
       "      <td>503.941105</td>\n",
       "      <td>603.324825</td>\n",
       "      <td>704.721330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>60.255556</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>60.911111</td>\n",
       "      <td>87.044444</td>\n",
       "      <td>68.233333</td>\n",
       "      <td>93.477778</td>\n",
       "      <td>52.844444</td>\n",
       "      <td>35.711111</td>\n",
       "      <td>55.366667</td>\n",
       "      <td>63.093827</td>\n",
       "      <td>...</td>\n",
       "      <td>748.469367</td>\n",
       "      <td>810.439308</td>\n",
       "      <td>581.758264</td>\n",
       "      <td>851.872620</td>\n",
       "      <td>838.614857</td>\n",
       "      <td>838.614857</td>\n",
       "      <td>851.872620</td>\n",
       "      <td>581.758264</td>\n",
       "      <td>810.439308</td>\n",
       "      <td>791.359113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>48.477778</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>44.122222</td>\n",
       "      <td>43.455556</td>\n",
       "      <td>49.155556</td>\n",
       "      <td>48.977778</td>\n",
       "      <td>62.066667</td>\n",
       "      <td>87.233333</td>\n",
       "      <td>52.380247</td>\n",
       "      <td>...</td>\n",
       "      <td>652.898833</td>\n",
       "      <td>796.302439</td>\n",
       "      <td>602.209314</td>\n",
       "      <td>498.463863</td>\n",
       "      <td>610.946722</td>\n",
       "      <td>610.946722</td>\n",
       "      <td>498.463863</td>\n",
       "      <td>602.209314</td>\n",
       "      <td>796.302439</td>\n",
       "      <td>527.242711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>148.288889</td>\n",
       "      <td>173.600000</td>\n",
       "      <td>125.600000</td>\n",
       "      <td>185.400000</td>\n",
       "      <td>219.388889</td>\n",
       "      <td>158.655556</td>\n",
       "      <td>122.555556</td>\n",
       "      <td>162.100000</td>\n",
       "      <td>134.788889</td>\n",
       "      <td>158.930864</td>\n",
       "      <td>...</td>\n",
       "      <td>1260.376081</td>\n",
       "      <td>1467.187007</td>\n",
       "      <td>3373.492517</td>\n",
       "      <td>1542.562306</td>\n",
       "      <td>1162.705363</td>\n",
       "      <td>1162.705363</td>\n",
       "      <td>1542.562306</td>\n",
       "      <td>3373.492517</td>\n",
       "      <td>1467.187007</td>\n",
       "      <td>1085.066092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>42.755556</td>\n",
       "      <td>30.411111</td>\n",
       "      <td>40.111111</td>\n",
       "      <td>76.622222</td>\n",
       "      <td>38.377778</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>46.844444</td>\n",
       "      <td>29.033333</td>\n",
       "      <td>42.077778</td>\n",
       "      <td>45.414815</td>\n",
       "      <td>...</td>\n",
       "      <td>456.442604</td>\n",
       "      <td>705.246073</td>\n",
       "      <td>557.641402</td>\n",
       "      <td>949.137819</td>\n",
       "      <td>1603.238833</td>\n",
       "      <td>1603.238833</td>\n",
       "      <td>949.137819</td>\n",
       "      <td>557.641402</td>\n",
       "      <td>705.246073</td>\n",
       "      <td>518.607121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5760 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              m1          m2          m3          m4          m5          m6  \\\n",
       "0      52.177778   41.044444   44.522222   59.300000   73.244444   60.322222   \n",
       "1      65.988889   68.444444   58.200000   61.166667   70.088889   59.588889   \n",
       "2      52.088889   43.633333   44.533333   83.066667   67.933333   52.477778   \n",
       "3      76.633333   55.400000   63.288889  154.366667  107.688889   92.022222   \n",
       "4      41.700000   31.333333   41.577778   44.500000   35.677778   65.966667   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "5755   48.933333   37.811111   42.133333   85.911111   62.555556   68.033333   \n",
       "5756   60.255556   54.000000   60.911111   87.044444   68.233333   93.477778   \n",
       "5757   48.477778   42.333333   45.600000   44.122222   43.455556   49.155556   \n",
       "5758  148.288889  173.600000  125.600000  185.400000  219.388889  158.655556   \n",
       "5759   42.755556   30.411111   40.111111   76.622222   38.377778   62.500000   \n",
       "\n",
       "              m7          m8          m9          mt  ...        f_iq1  \\\n",
       "0      56.977778   69.855556   55.388889   56.981481  ...   441.040214   \n",
       "1      51.922222   45.711111   44.688889   58.422222  ...   511.632988   \n",
       "2      52.411111   45.533333   44.933333   54.067901  ...   342.123918   \n",
       "3     102.311111   68.300000   64.022222   87.114815  ...  1199.087034   \n",
       "4      79.611111   30.533333   47.644444   46.504938  ...   673.920234   \n",
       "...          ...         ...         ...         ...  ...          ...   \n",
       "5755  105.711111   75.911111   75.444444   66.938272  ...   734.803565   \n",
       "5756   52.844444   35.711111   55.366667   63.093827  ...   748.469367   \n",
       "5757   48.977778   62.066667   87.233333   52.380247  ...   652.898833   \n",
       "5758  122.555556  162.100000  134.788889  158.930864  ...  1260.376081   \n",
       "5759   46.844444   29.033333   42.077778   45.414815  ...   456.442604   \n",
       "\n",
       "            f_iq2        f_iq3        f_iq4        f_iq5        f_iq6  \\\n",
       "0      475.770372   686.422356   562.510183   647.224406   647.224406   \n",
       "1      502.491063   542.115355   482.229770   916.884994   916.884994   \n",
       "2      528.351686   572.593738   785.070872   634.955719   634.955719   \n",
       "3     1107.890541   866.829986   842.717586   878.426867   878.426867   \n",
       "4     1246.701313   595.913625   468.292469   443.726750   443.726750   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5755   603.324825   503.941105   497.120977   789.305868   789.305868   \n",
       "5756   810.439308   581.758264   851.872620   838.614857   838.614857   \n",
       "5757   796.302439   602.209314   498.463863   610.946722   610.946722   \n",
       "5758  1467.187007  3373.492517  1542.562306  1162.705363  1162.705363   \n",
       "5759   705.246073   557.641402   949.137819  1603.238833  1603.238833   \n",
       "\n",
       "            f_iq7        f_iq8        f_iq9       f_iqrt  \n",
       "0      562.510183   686.422356   475.770372   590.006178  \n",
       "1      482.229770   542.115355   502.491063   491.380149  \n",
       "2      785.070872   572.593738   528.351686  2659.003215  \n",
       "3      842.717586   866.829986  1107.890541  1091.394490  \n",
       "4      468.292469   595.913625  1246.701313   484.947378  \n",
       "...           ...          ...          ...          ...  \n",
       "5755   497.120977   503.941105   603.324825   704.721330  \n",
       "5756   851.872620   581.758264   810.439308   791.359113  \n",
       "5757   498.463863   602.209314   796.302439   527.242711  \n",
       "5758  1542.562306  3373.492517  1467.187007  1085.066092  \n",
       "5759   949.137819   557.641402   705.246073   518.607121  \n",
       "\n",
       "[5760 rows x 182 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([res_stat,res_fft],axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "enormous-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data attributes\n",
    "data = preprocessing.scale(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-genetics",
   "metadata": {},
   "source": [
    "## Trying different versions of SVM using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "seventh-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take all our penguin data, and reserve 20% of it for testing \n",
    "X_train, X_test, y_train, y_test = train_test_split(data, df_y, test_size=0.3,random_state=42, stratify=df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "electronic-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    " #                    'C': [1, 10, 100, 1000]},\n",
    "  #                  {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "golden-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3],\n",
    "                     'C': [.01,.1, 1, 10, 100, 1000]},\n",
    "                   {'kernel': ['linear'], 'C': [.01 ,.1 ,1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "infrared-nutrition",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [01:24<01:24, 84.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.728 (+/-0.291) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.935 (+/-0.007) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.968 (+/-0.010) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.007) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.003) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.986 (+/-0.006) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.011) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.989 (+/-0.003) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.981 (+/-0.005) for {'C': 1, 'kernel': 'linear'}\n",
      "0.978 (+/-0.008) for {'C': 10, 'kernel': 'linear'}\n",
      "0.978 (+/-0.008) for {'C': 100, 'kernel': 'linear'}\n",
      "0.978 (+/-0.008) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.98      0.98       432\n",
      "           2       0.97      0.99      0.98       432\n",
      "           3       0.98      0.98      0.98       432\n",
      "           4       0.99      0.99      0.99       432\n",
      "\n",
      "    accuracy                           0.98      1728\n",
      "   macro avg       0.98      0.98      0.98      1728\n",
      "weighted avg       0.98      0.98      0.98      1728\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [02:54<00:00, 87.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.736 (+/-0.232) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.932 (+/-0.009) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.967 (+/-0.010) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.007) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.988 (+/-0.003) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.986 (+/-0.007) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.011) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.989 (+/-0.003) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.981 (+/-0.005) for {'C': 1, 'kernel': 'linear'}\n",
      "0.978 (+/-0.008) for {'C': 10, 'kernel': 'linear'}\n",
      "0.978 (+/-0.008) for {'C': 100, 'kernel': 'linear'}\n",
      "0.978 (+/-0.008) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      0.98      0.98       432\n",
      "           2       0.97      0.99      0.98       432\n",
      "           3       0.98      0.98      0.98       432\n",
      "           4       0.99      0.99      0.99       432\n",
      "\n",
      "    accuracy                           0.98      1728\n",
      "   macro avg       0.98      0.98      0.98      1728\n",
      "weighted avg       0.98      0.98      0.98      1728\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 2/2 [02:54<00:00, 87.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "for score in tqdm(scores):\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Note the problem is too easy: the hyperparameter plateau is too flat and the\n",
    "# output model is the same for precision and recall with ties in quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "considerable-alcohol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=df_y.columns,\n",
    "            yticklabels=df_y.columns)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "superb-mason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9952876984126985\n",
      "0.9837962962962964\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(X_train,y_train))\n",
    "print(clf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "practical-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-puppy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-container",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-cotton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-explorer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-annex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-isaac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-religious",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-halloween",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "herbal-samba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-danger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-carrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-letter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-surprise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-convertible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-petersburg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-success",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "golden-development",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-rates",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-dominican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-flood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-hamburg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-mason",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
